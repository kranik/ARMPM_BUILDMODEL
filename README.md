# Power model generation for ARM big.LITTLE aka ARMPM\_BUILDMODEL

**September 2017 - The code is no loger actively maintained, though I have some plans for a possuble update on the multi-thread model methodology.**

**March 2018 - I have officially graduated, so this project is currently closed.**

**February 2019 - Project reopened due to interested from other academic parties.**

Full details about the methodology and the produced models are presented in the dissertation [**Power Modelling and Analysis on Heterogeneous Embedded Systems**](https://seis.bristol.ac.uk/~eejlny/downloads/kris_thesis.pdf).

## Getting Started

The scripts contained in this repo represent the second part of the power modelling and analysis methodology, that I have developed as part of my PhD, namely the offline model generation and analysis. They work with the on-platform data gathered by the [ARMPM\_DATACOLLECT](https://github.com/kranik/ARMPM_DATACOLLECT) scripts. 

The whole model generation and validation process takes multiple steps:
1. Run the [ARMPM\_DATACOLLECT](https://github.com/kranik/ARMPM_DATACOLLECT) on the platform and obtain PMU event and power sensor samples from the platform.
2. Concatenate all the data files using timestamps from the samples using [`XU3_results.sh`](Scripts/XU3_results.sh).
3. Analyse the concatenated data files using [`octave_makemodel.sh`](Scripts/octave_makemodel.sh)

The [`octave_makemodel.sh`](Scripts/octave_makemodel.sh) script does both the model generation and validaton in a two-step process, but within the same code. All the scripts are written in bash, but use a lot of supporting linux commands to manipulate files and calculate model coefficients as well as using command line calls to [_Octave_](https://www.gnu.org/software/octave/) for more complex mathematical capabilities of the language.

This repo contains only the control scripts and does not include a version of octave, nor any example result files for analysis. This is done to minimize the repo size and also since github has a filesize limit (_though I might include some examples in the future_).

### Prerequisites

The script use `GNU bash, version 4.3.48(1)-release (x86_64-pc-linux-gnu)` and the platform is built on `Ubuntu 16.04.3 LTS (Xenial Xerus)`, kernel version `4.4.0-116-generic`. However the mothodology should be portable to other systems, since the scripts primarily use standart command line programs, such as `awk`, `sed`, `bc`, etc. and calls to `octave`. The project uses `GNU Octave, version 4.0.2` and should work with higher versions as well. Please check with your distro package database for the appropriate octave version or download and compile from [here](https://ftp.gnu.org/gnu/octave/).

**DISCLAIMER - I haven't really tested the scripts on other setups but my own so please let me know if you have any issues via [email](mailto:kris.nikov@bris.ac.uk).**

### Setup

Use `git clone git@github.com:kranik/ARMPM_DATACOLLECT.git` to clone the repo. Make sure to do `chmod +x` on all the executable scripts so that they function correctly. Then install octave and make sure to update your `$PATH` to include the octave binary since the [`octave_makemodel.sh`](Scripts/octave_makemodel.sh) uses a call to `octave --silent --eval "load_build_model(...)"` to compute the models. Again these scripts are intended to work with the platform data generated by [ARMPM\_DATACOLLECT](https://github.com/kranik/ARMPM_DATACOLLECT) though if you provide files with the same format of the samples the scripts should still generate models. 

## Usage

After obtaining on-platform samples using the [_ARMPM\_DATACOLLECT_](https://github.com/kranik/ARMPM_DATACOLLECT) script/format the first step is to use the [`XU3_results.sh`](Scripts/XU3_results.sh) to analyse the data files with the power and PMU event samples and reformat the data for easy processing. That script uses calls to two supporting scripts [`process_raw_events.sh`](Scripts/process_raw_events.sh) and [`concatenate_results.sh`](Scripts/concatenate_results.sh), which in turn syncronize the power sensor and PMU event samples with the benchmark start and end date information to produce one large file in the following format:

```
#Timestamp	Benchmark	Run(#)	CPU(4) Frequency(MHz)	CPU(4) Temperature(C)	A15 Voltage(V)	A15 Current(A)	A15 Power(W)	CPU_CYCLES	L1I_CACHE_REFILL	L1I_TLB_REFILL	L1D_CACHE_ACCESS	L1D_TLB_REFILL	INST_RETIRED	EXCEPTION_TAKEN
1495799541911182792	parsec.dedup	1	1800	31	1.100000	0.469000	0.560000	545522980	5565229	1618872	122886684	1905462	242767835	27575
1495799542421250667	parsec.dedup	1	1800	32	1.100000	1.126000	1.348000	861434859	9003064	2606109	189346119	3058250	367420711	45310
1495799542931347334	parsec.dedup	1	1800	33	1.100000	1.129000	1.352000	873278984	8932811	2596105	197463907	3061025	391550539	45281
1495799543442541950	parsec.dedup	1	1800	33	1.100000	1.145000	1.371000	587130297	3463475	1858825	127304924	2161852	202394566	13916
...
```
Since the PMU of the ARM Cortex-A15 and Cortex-A7 which the project is based around is limited and can collect a small number of events concurrently, multiple workload executions are required to collect multiple sets of events in order to do a thorough exploration and identify the absolute best set. To facilitate this I have also developed the [`XU3_merge_events.sh`](Scripts/XU3_merge_events.sh) and [`XU3_merge_multithread.sh`](Scripts/XU3_merge_multithread.sh) scripts. They take the individual results files for each set of events, produced by [`XU3_results.sh`](Scripts/XU3_results.sh) and then syncronize and concatenate the events together in one big data file. This process is complicated since the samples themselves have different timestamps so this is an approximation of what the data would be if the PMU could collect all the events concurrently. Here is an example of the final data file with all events merged: 

```
#Timestamp	Benchmark	Run(#)	CPU(4) Frequency(MHz)	CPU(4) Temperature(C)	A15 Voltage(V)	A15 Current(A)	A15 Power(W)	CPU_CYCLES	SW_INCR	L1I_CACHE_REFILL	L1I_TLB_REFILL	L1D_CACHE_REFILL	L1D_CACHE_ACCESS	L1D_TLB_REFILL	INST_RETIRED	EXCEPTION_TAKEN	EXCEPTION_RETURN	CID_WRITE_RETIRED	BRANCH_MISPRED	BRANCH_PRED	DATA_MEM_ACCESS	L1I_CACHE_ACCESS	L1D_CACHE_WB	L2D_CACHE_ACCESS	L2D_CACHE_REFILL	L2D_CACHE_WB	BUS_ACCESS	LOCAL_MEMORY_ERROR	INST_SPEC_EXEC	TTBR_WRITE_RETIRED	BUS_CYCLES	L1D_READ_ACCESS	L1D_WRITE_ACCESS	L1D_READ_REFILL	L1D_WRITE_REFILL	L1D_WB_VICTIM	L1D_WB_CLEAN_COHERENCY	L1D_INVALIDATE	L1D_TLB_READ_REFILL	L1D_TLB_WRITE_REFILL	L2D_READ_ACCESS	L2D_WRITE_ACCESS	L2D_READ_REFILL	L2D_WRITE_REFILL	L2D_WB_VICTIM	L2D_WB_CLEAN_COHERENCY	L2D_INVALIDATE	BUS_READ_ACCESS	BUS_WRITE_ACCESS	BUS_NORMAL_ACCESS	BUS_NOT_NORMAL_ACCESS	BUS_NORMAL_ACCESS_2	BUS_PERIPH_ACCESS	DATA_MEM_READ_ACCESS	DATA_MEM_WRITE_ACCESS	UNALIGNED_READ_ACCESS	UNALIGNED_WRITE_ACCESS	UNALIGNED_ACCESS	INST_SPEC_EXEC_LDREX	INST_SPEC_EXEC_STREX_PASS	INST_SPEC_EXEC_STREX_FAIL	INST_SPEC_EXEC_LOAD	INST_SPEC_EXEC_STORE	INST_SPEC_EXEC_LOAD_STORE	INST_SPEC_EXEC_INTEGER_INST	INST_SPEC_EXEC_SIMD	NST_SPEC_EXEC_VFP	INST_SPEC_EXEC_SOFT_PC	BRANCH_SPEC_EXEC_IMM_BRANCH	BRANCH_SPEC_EXEC_RET	BRANCH_SPEC_EXEC_IND	BARRIER_SPEC_EXEC_ISB	BARRIER_SPEC_EXEC_DSB	BARRIER_SPEC_EXEC_DMB
1481859038711873008	automotive_bitcount	1	2000	56	1.3	.940	1.245	633041009	0	251073	74536	59355	93218664	88574	977984190	920	1512	4	4242725	130220913	93203660	234785393	21103	382128	27664	5158	155440	0	1073877121	8	126998299	73919626	19246408	48354	6986	18413	1797	1075	80983	7275	313696	61659	23565	3443	4928	54	1640	114460	38406	151064	1686	148560	1676	73942135	19239660	26305	27692	54009	26284	24958	50	69554105	3803042	73278476	842154951	4	276	130141812	99415136	15407233	30773853	148	9651	35696
1481859039220655512	automotive_bitcount	1	2000	57	1.3	1.663	2.206	1001618917	0	42302	17154	9654	115727477	18122	1577397597	109	218	0	6635218	202043052	129668133	360264178	4105	65539	2037	12	14525	0	1710017202	0	200304433	103864329	25867854	6496	1554	2567	1055	783	18204	1694	58231	7249	1110	1181	46	0	1095	11921	1109	10584	2430	9304	2430	103037335	25918914	7542	7998	15770	6400	4924	22	95654475	3678953	99088064	1379928023	0	0	201907526	157986185	22319355	44543946	6	2998	6656
1481859039729359565	automotive_bitcount	1	2000	58	1.3	1.668	2.213	1001187702	0	43467	18870	9583	134877023	17897	1578593158	109	218	0	6676714	188991770	98206557	356391091	4294	67553	2321	9	11556	0	1724083416	0	200232988	77633219	20527362	6496	1580	2530	1109	820	18006	1476	55711	7494	927	1232	7	0	981	9868	970	8372	2416	7944	2416	78411625	20475011	7608	7528	14840	6128	4651	53	101281623	2578616	77448402	1436266059	0	0	189745716	151979326	18570970	37107001	6	2977	6574
...
```

I have two versions of the event merge script for the single-thread/core and the multi-thread/core models since I view them as separate modelling cases. In my experiments I isolate one thread per core, which is why I use the terms thread and core interchangeably, though I understand that may not be the case in other scenarios. The difference between [`XU3_merge_multithread.sh`](Scripts/XU3_merge_multithread.sh) and [`XU3_merge_events.sh`](Scripts/XU3_merge_events.sh) is that the multi-thread specific merge script identifies and accounts for the number of cores used in the execution and there is specific information in the data files representing that.

I also have two supporting scripts - [`truncate_event_columns.sh`](Scripts/truncate_event_columns.sh) and [`XU3_results_splitruns.sh`](Scripts/XU3_results_splitruns.sh). The former helps remove specific columns from the data files in case you want to remove unusable or unwanted events from the analysis (or shrink filesize) and the latter isolates different runs into separate files and can be used to compare event variation between different workload executions to identify variability of the platform/methodology overhead. These scripts are not an essential part of the workflow but can help with data analysis in specific scenarios.

The final and most important part of the methodology is the model generation and validation script [`octave_makemodel.sh`](Scripts/octave_makemodel.sh), which uses the concatenated and merged data files with all the PMU events and sensor information and generates the models using calls to `octave`. An important part of the script is the ability to specify the benchmaks used for training and testing the models, which need to be put in an input file passed to the script. Here is an example of the split of the PARSEC benchmakrs I used with for the multi-thread models:

```
#Train Set	Test Set
parsec.facesim	parsec.dedup
splash2x.radiosity	parsec.freqmine
splash2x.raytrace	parsec.streamcluster
splash2x.water_nsquared	splash2x.barnes
	splash2x.fmm
```  

The benchmark split file needs to have a specific header and two columns for the train and test set with the benchmark names distributed between the two categories. The `octave` scripts that I have produced, namely [`build_model.m`](Scripts/build_model.m) and [`load_build_model.m`](Scripts/load_build_model.m) use the train set and test set data passed to them by [`octave_makemodel.sh`](Scripts/octave_makemodel.sh) and use Ordinary Lease Squares to fit the model on the train set and validate the resulting model error using the test set. More information about what heuristics I use to identify the best set of events and the model optimisation criteria are explained in details in my [dissertation](https://seis.bristol.ac.uk/~eejlny/downloads/kris_thesis.pdf). 

### Troubleshooting

All the scripts have a `-h` flag which lists the possible number of inputs/flags and explains what their functionality is. An example is given below:
```
$ ./octave_makemodel.sh -h
Available flags and options:
-r [FILEPATH] -> Specify the concatednated result file to be analyzed.
-t [FILEPATH] -> Specify the concatednated result file to be used to test model.
-f [FREQENCY LIST][MHz] -> Specify the frequencies to be analyzed, separated by commas.
-b [FILEPATH] -> Specify the benchmark split file for the analyzed results. Can also use an unused filename to generate new split.
-p [NUMBER] -> Specify power column.
-e [NUMBER LIST] -> Specify events list.
-a -> Use flag to specify all frequencies model instead of per frequency one.
-x [NUMBER: 1:2]-> Select cross model computation mode: 1 -> Intra-core model (no -t, just use -r onto intself but with a cross-model methodology); 2 -> Inter-core cross-model (-r file to -t file and they should have differing frequency information, but same events list);
-q [FREQENCY LIST][MHz] -> Specify the frequencies to be used in cross-model for the second core (specified with -t flag).
-m [NUMBER: 1:3]-> Type of automatic machine learning search method: 1 -> Bottom-up; 2 -> Top-down; 3 -> Exhaustive search;
-c [NUMBER: 1:4]-> Select minimization criteria for model optimisation: 1 -> Absolute error; 2 -> Absolute error standart deviation; 3 -> Maximum event cross-correlation; 4 -> Average event cross-correlation;
-l [NUMBER LIST] -> Specify events pool.
-n [NUMBER] -> Specify max number of events to include in automatic model generation.
-o [NUMBER: 1:5]-> Output mode: 1 -> Measured platform physical data; 2 -> Model detailed performance and coefficients; 3 -> Model shortened performance; 4 -> Platform selected event totals; 5 -> Platform selected event averages;
-s [FILEPATH] -> Specify the save file for the analyzed results.
Mandatory options are: -r, -b, -p, -e/(-m -c -n -l), -o
```

The code is also heavily commented, so please check the source first before sending me a message.

## Contributing

So far I am the sole contributor, but if this project gets traction I will generate a proper Code of Conduct document and set some rules. For now please use the [ShellCheck](https://www.shellcheck.net/) bash code linter to verify your code and comment thoroughly. 

## Author

The work presented here was carried out almost entirely by me (so far), [Dr Kris Nikov](mailto:kris.nikov@bris.ac.uk) as part of my PhD project in the Department of Electrical and Electronic Enginnering at the Univeristy of Bristol, UK. I have received some minor contrubutions such as the initial code for the OLS model fitting in octave, given to me by my academic supervisor [Dr Jose Nunez-Yanez](http://www.bristol.ac.uk/engineering/people/jose-l-nunez-yanez/overview.html). I have also used a kernel patch, provided by my industrial supervisor [Dr Matt Horsnell](https://uk.linkedin.com/in/matthorsnell), which enables the on-board PMU on the ODROID-XU3 development board.

## Licence

This project is licensed under the BSD-3 License - please see [LICENSE.md](LICENSE.md) for more details.

## Acknowledgements

The primary project supervisor was [Dr Jose Nunez-Yanez](http://www.bristol.ac.uk/engineering/people/jose-l-nunez-yanez/overview.html). This work was initially supported by [ARM Research](https://www.arm.com/resources/research) funding, through an EPSRC iCASE studentship and the [University of Bristol](http://www.bristol.ac.uk/doctoral-college/) and by the EPSRC ENEAC grant number EP/N002539/1. Industrial project supervisor was [Dr Matt Horsnell](https://uk.linkedin.com/in/matthorsnell)
